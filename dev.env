# Introduction
# ------------
# This project uses environment variable for configuration.
# To make it easier, .env files are used.
#
# How does it work?
# -----------------
# When a deployment is done using our docker-compose.yaml file, all variable declared
# bellow are added to the containers as environment variables.
# Our apps then read them to run with provided parameters.
#
# Am I supposed to add them on my machine as well?
# ------------------------------------------------
# No. Our settings first read environment variables defined on the machine.
# When missing, they are looking for a file called ".env".
# If you look into the source code of the "backend" or "datascience" projects,
# you can notice a file called ".env", which is a symlink pointing by default to
# "dev.env". If you want to use another .env file, you can use the commands bellow:
#
# ```shell
# cd backend
# ln -s ../name_of_you_env_file .env
# ```
#
# Documentation
# -------------
# For more information, please consult the documentation:
# https://github.com/JoffreyLGT/e-commerce-mlops

# -----------------------------------------------------
# Docker configuration
# -----------------------------------------------------

# Docker project name displayed when checking containers list
DOCKER_PROJECT_NAME="product-classification-dev"

# Network used in Docker for both signoz and our containers
DOCKER_NETWORK=product-classification

# Target environment must be development, staging or production
TARGET_ENV=development

# Environment file with all env variables to inject in containers
ENV_FILE=dev.env

# Directory to which product data volume is mounted
DATA_DIR=data
# Sub directory in DATA_DIR in which we store products images temporarily
TEMPORARY_PRODUCT_IMAGES_DIR="temp_products_images"
# Sub directory in DATA_DIR in which we store products images we want to keep
PRODUCTS_IMAGES_DIR="products_images"

# -----------------------------------------------------
# dev environment configuration
# -----------------------------------------------------

# True to force the reset of venv during projects setup
# Used in scripts/environment-setup.sh
RESET_VENV=false

# True to use DB container instead of local PostgreSQL
# Only used for local installation, since dev container has $IS_DEV_CONTAINER=true
USE_DB_CONTAINER=true

# -----------------------------------------------------
# backend project
# -----------------------------------------------------

# Name of the backend container
BACKEND_SERVER="127.0.0.1"
# FastAPI port forwarded to host
BACKEND_FASTAPI_PORT=8010
# Name of the db container
DB_SERVER="127.0.0.1"

# Displayed in FastAPI documentation
PROJECT_NAME="Product Classification"

# Used to provide SERVER_NAME and SERVER_HOST env variable to FastAPI
DOMAIN=127.0.0.1

# Used to encode JWT tokens
# Should be stored in secrets
SECRET_KEY=changethis

# Admin user created in DB to use the API
# Outside of dev environment, you should store them in secrets
FIRST_ADMINUSER=admin@test.com
FIRST_ADMINUSER_PASSWORD=changethis

# CORS origin to accept API requests
BACKEND_CORS_ORIGINS=["http://127.0.0.1:8000"]

# Connection information to send telemetry to Signoz
OTEL_RESOURCE_ATTRIBUTES="service.name=product-classification-dev-api"
OTEL_EXPORTER_OTLP_ENDPOINT="http://otel-collector:4318"

# Postgres database name
POSTGRES_DB=product-classification-dev

# First PostgreSQL admin user
# Outside of dev environment, you should store them in secrets
POSTGRES_USER=admin
POSTGRES_PASSWORD=changethis

# -----------------------------------------------------
# datascience
# -----------------------------------------------------

# Name of the datascience server on the network
DATASCIENCE_SERVER="127.0.0.1"
# Port on which fusion model is served
DATASCIENCE_MODEL_PORT=5022
# Port on which mlflow ui is served
DATASCIENCE_MLFLOW_PORT=5023

# --- Docker compose service ---

# Define the location of the local data folder
# Must be relative to docker-compose.yml directory
DATA_VOLUME_SRC="./backend/data"

# --- CommonSettings ---

# Define the minimum log level to print in console
# Possible values are "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"
CONSOLE_LOG_LEVEL="INFO"
FILE_LOG_LEVEL="INFO"

# Define where logs are stored
LOGS_DIR="logs"
LOGS_FILE_NAME="datascience.log.json"

# --- TrainingSettings ---

# Artifacts files name
TEXT_IDFS_FILE_NAME="text_idfs.json"
TEXT_VOCABULARY_FILE_NAME="text_vocabulary.json"
TRAINING_HISTORY_FILE_NAME="training_history.png"
CLASSIFICATION_REPORT_FILE_NAME="classifaction_report.txt"
CONFUSION_MATRIX_FILE_NAME="confusion_matrix.png"
REQUIREMENTS_FILE_NAME="requirements.txt"

# MLFlow configurations
MLFLOW_REGISTRY_URI="mlruns"
MLFLOW_TRACKING_URI="mlruns"

# Create default model (text, image and fusion) in MLFlow if they don't exists
MLFLOW_SET_DEFAULT_MODELS=True

# --- DatasetSettings ---

IMG_PROCESSING_NB_THREAD=4
# Directory where data used to train the models are stored. Must contain the files bellow:
# originals
# ├── X.csv  Contains the features: [linenumber,designation,description,productid,imageid]
# ├── images Contains one image per product named "image_{imageid}_product_{productid}.jpg"
# └── y.csv  Contains the target: prdtypecode
# Can be either a direct path (starting with /)
# or a relative path using datascience as root (ex: "data" for "datascience/data")
ORIGINAL_DATA_DIR="data/originals"
# Directory where remaining data (not already in a dataset) are stored
REMAINING_DATA_DIR="data/datasets/_remaining"

# --- MobileNetImageModelSettings ---
IMG_WIDTH=224
IMG_HEIGHT=224
IMG_KEEP_RATIO=True
IMG_GRAYSCALED=False
